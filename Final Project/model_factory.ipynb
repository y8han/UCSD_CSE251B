{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "import itertools\n",
    "#from constants import *\n",
    "from file_utils import read_file_in_dir\n",
    "from generator import define_G\n",
    "from discriminator import define_D\n",
    "\n",
    "class CycleGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, config_data):\n",
    "        super().__init__()\n",
    "        self.lr = config_data['cycleGAN']['lr']\n",
    "        self.criterionGAN = nn.MSELoss()\n",
    "        self.criterionCycle = torch.nn.L1Loss()\n",
    "        if torch.cuda.is_available():\n",
    "            self.criterionGAN = self.criterionGAN.to(\"cuda\")\n",
    "            self.criterionCycle = self.criterionCycle.to(\"cuda\")\n",
    "        \n",
    "        self.register_buffer('real_label', torch.tensor(1.0))\n",
    "        self.register_buffer('fake_label', torch.tensor(0.0))\n",
    "        \n",
    "        \n",
    "        self.model_G_A = define_G(3, 3, 64, 'unet_128', 'instance', use_dropout=True)\n",
    "        self.model_G_B = define_G(3, 3, 64, 'unet_128', 'instance', use_dropout=True)\n",
    "    \n",
    "        self.model_D_A = define_D(3, 64, n_layers_D=3, use_sigmoid=True)\n",
    "        self.model_D_B = define_D(3, 64, n_layers_D=3, use_sigmoid=True)\n",
    "        \n",
    "        # changes needed\n",
    "        #torch.nn.init.xavier_uniform(self.model_G_A.weight.data)\n",
    "        #torch.nn.init.xavier_uniform(self.model_G_B.weight)\n",
    "        #torch.nn.init.xavier_uniform(self.model_D_A.weight)\n",
    "        #torch.nn.init.xavier_uniform(self.model_D_B.weight)\n",
    "        self.optimizerG = torch.optim.Adam(itertools.chain(self.model_G_A.parameters(), self.model_G_B.parameters()), lr=self.lr)\n",
    "        self.optimizerD = torch.optim.Adam(itertools.chain(self.model_D_A.parameters(), self.model_D_B.parameters()), lr=self.lr)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_image):\n",
    "        '''G_A is generating A from B and G_B is generating B from A'''\n",
    "        self.real_A = input_image['A']\n",
    "        self.real_B = input_image['B']\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.real_A = self.real_A.to(\"cuda\")\n",
    "            self.real_A = self.real_B.to(\"cuda\")\n",
    "        \n",
    "        #G_A(B)\n",
    "        self.fake_A = self.model_G_A(self.real_B)\n",
    "        \n",
    "        #G_B(A)\n",
    "        self.fake_B = self.model_G_B(self.read_A)\n",
    "        \n",
    "        #G_A(G_B(A))\n",
    "        self.recreate_A = self.model_G_A(self.fake_B)\n",
    "        \n",
    "        #G_B(G_A(B))\n",
    "        self.recreate_B = self.model_G_B(self.fake_A)\n",
    "    def basic_D_backward(self, model_D, real, fake):\n",
    "        pred_real = model_D(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, self.real_label.expand_as(pred_real))\n",
    "        pred_fake = model_D(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, self.fake_label.expand_as(pred_fake))\n",
    "        # Combined loss and calculate gradients\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "    def D_A_backward(self, real, fake):\n",
    "        '''D_A is discriminate A'''\n",
    "        self.loss_D_A = self.basic_D_backward(self.model_D_A, self.real_A, self.fake_A)\n",
    "    def D_B_backward(self, real, fake):\n",
    "        self.loss_D_B = self.basic_D_backward(self.model_D_B, self.real_B, self.fake_B)\n",
    "    def backward_G(self):\n",
    "        check_G_A = self.model_D_A(self.fakeA)\n",
    "        self.loss_G_A = self.criterionGAN(check_G_A,self.real_label.expand_as(check_G_A))\n",
    "        check_G_B = self.model_D_B(self.fakeB)\n",
    "        self.loss_G_B = self.criterionGAN(check_G_B,self.real_label.expand_as(check_G_B))\n",
    "        self.loss_cycle_A = self.criterionCycle(self.recreate_A, self.real_A) * self.lambda_A\n",
    "        self.loss_cycle_B = self.criterionCycle(self.recreate_B, self.real_B) * self.lambda_B\n",
    "        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B\n",
    "        self.loss_G.backward()\n",
    "    def update(self):\n",
    "        self.forward()\n",
    "        self.set_model_grad([self.model_D_A, sel.model_D_B], False)\n",
    "        self.optimizerG.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizerG.step()\n",
    "        self.set_model_grad([self.model_D_A, sel.model_D_B], True)\n",
    "        self.optimizerD.zero_grad()\n",
    "        self.D_A_backward()\n",
    "        self.D_B_backward()\n",
    "        self.optimizerD.step()\n",
    "        \n",
    "    def set_model_grad(self, nets, requires):\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for para in net.parameters():\n",
    "                    para.require_grad = requires\n",
    "        \n",
    "        \n",
    "def get_model(config_data):\n",
    "    return CycleGAN(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = read_file_in_dir('./','parameter.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'LeakyReLu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06d11484d559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-e9fb3a078a00>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(config_data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-e9fb3a078a00>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_G_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unet_128'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_D_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_D_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UCSD_CSE251B/Final Project/discriminator.py\u001b[0m in \u001b[0;36mdefine_D\u001b[0;34m(input_nc, ndf, n_layers_D, use_sigmoid)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# make sure the number of layers should be 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnetD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLayerDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UCSD_CSE251B/Final Project/discriminator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_nc, ndf, n_layers, use_sigmoid)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             ]\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# In order to specify the PatchGan to be 70 * 70, we need to have five layers. (more or less layers are wrong)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'LeakyReLu'"
     ]
    }
   ],
   "source": [
    "a = get_model(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
