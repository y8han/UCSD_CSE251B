{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# CSE 253: Programming Assignment 4\n",
    "# Code snippet by Ajit Kumar, Savyasachi\n",
    "# Fall 2020\n",
    "################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from caption_utils import *\n",
    "from constants import ROOT_STATS_DIR\n",
    "from dataset_factory import get_datasets\n",
    "from file_utils import *\n",
    "from model_factory import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-aaec1d1e7895>, line 107)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-aaec1d1e7895>\"\u001b[0;36m, line \u001b[0;32m107\u001b[0m\n\u001b[0;31m    else;\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Class to encapsulate a neural experiment.\n",
    "# The boilerplate code to setup the experiment, log stats, checkpoints and plotting have been provided to you.\n",
    "# You only need to implement the main training logic of your experiment and implement train, val and test methods.\n",
    "# You are free to modify or restructure the code as per your convenience.\n",
    "class Experiment(object):\n",
    "    def __init__(self, name):\n",
    "        config_data = read_file_in_dir('./', name + '.json')\n",
    "        if config_data is None:\n",
    "            raise Exception(\"Configuration file doesn't exist: \", name)\n",
    "\n",
    "        self.__name = config_data['experiment_name']\n",
    "        self.__experiment_dir = os.path.join(ROOT_STATS_DIR, self.__name)\n",
    "\n",
    "        # Load Datasets\n",
    "        self.__coco_test, self.__vocab, self.__train_loader, self.__val_loader, self.__test_loader = get_datasets(\n",
    "            config_data)\n",
    "\n",
    "        # Setup Experiment\n",
    "        self.__generation_config = config_data['generation']\n",
    "        self.__epochs = config_data['experiment']['num_epochs']\n",
    "        self.__learningrate = config_data['experiment']['learning_rate']\n",
    "        self.__current_epoch = 0\n",
    "        self.__training_losses = []\n",
    "        self.__val_losses = []\n",
    "        self.__best_model = None  # Save your best model in this field and use this in test method.\n",
    "\n",
    "        # Init Model\n",
    "        self.__model = get_model(config_data, len(self.__vocab))\n",
    "\n",
    "        # TODO: Set these Criterion and Optimizers Correctly\n",
    "        self.__criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.__optimizer = torch.optim.Adam(self.__model.parameters(), lr = self.__learningrate,weight_decay=0.01)\n",
    "        self.__init_model()\n",
    "        self.__stochastic = not config_data['generation']['deterministic']\n",
    "\n",
    "        # Load Experiment Data if available\n",
    "        self.__load_experiment()\n",
    "        \n",
    "        self.__early_stop_mark = 0\n",
    "        self.__early_stop= config_data['experiment']['early_stop']\n",
    "        if len(self.__val_losses) == 0:\n",
    "            self.__best_val_loss = 100\n",
    "        else:\n",
    "            self.__best_val_loss = min(self.__val_losses)\n",
    "\n",
    "    # Loads the experiment data if exists to resume training from last saved checkpoint.\n",
    "    def __load_experiment(self):\n",
    "        os.makedirs(ROOT_STATS_DIR, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(self.__experiment_dir):\n",
    "            self.__training_losses = read_file_in_dir(self.__experiment_dir, 'training_losses.txt')\n",
    "            self.__val_losses = read_file_in_dir(self.__experiment_dir, 'val_losses.txt')\n",
    "            self.__current_epoch = len(self.__training_losses)\n",
    "\n",
    "            state_dict = torch.load(os.path.join(self.__experiment_dir, 'latest_model.pt'))\n",
    "            self.__model.load_state_dict(state_dict['model'])\n",
    "            self.__optimizer.load_state_dict(state_dict['optimizer'])\n",
    "\n",
    "        else:\n",
    "            os.makedirs(self.__experiment_dir)\n",
    "\n",
    "    def __init_model(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.__model = self.__model.cuda().float()\n",
    "            self.__criterion = self.__criterion.cuda()\n",
    "\n",
    "    # Main method to run your experiment. Should be self-explanatory.\n",
    "    def run(self):\n",
    "        start_epoch = self.__current_epoch\n",
    "        for epoch in range(start_epoch, self.__epochs):  # loop over the dataset multiple times\n",
    "            start_time = datetime.now()\n",
    "            self.__current_epoch = epoch\n",
    "            train_loss = self.__train()\n",
    "            val_loss = self.__val()\n",
    "            self.__record_stats(train_loss, val_loss)\n",
    "            self.__log_epoch_stats(start_time)\n",
    "            \n",
    "            if val_loss > self.__best_val_loss:\n",
    "                self.__early_stop_mark += 1\n",
    "                if self.__early_stop_mark >= self.__early_stop and self.__early_stop != 0:\n",
    "                    print(\"Early Stopped\")\n",
    "                    break\n",
    "            else:\n",
    "                self.__save_model()\n",
    "                self.__early_stop_mark = 0\n",
    "                self.__best_val_loss = val_loss\n",
    "\n",
    "    # TODO: Perform one training iteration on the whole dataset and return loss value\n",
    "    def __train(self):\n",
    "        self.__model.train()\n",
    "        training_loss = 0\n",
    "\n",
    "        for i, (images, captions, _) in enumerate(self.__train_loader):\n",
    "            self.__optimizer.zero_grad()\n",
    "            images = images.to('cuda')\n",
    "            captions = captions.to('cuda')\n",
    "            outputs = self.__model(images, captions)\n",
    "            outputs = torch.transpose(outputs, 1, 2)\n",
    "            captions = captions[:,1:]\n",
    "            outputs = outputs[:, :, :-1]\n",
    "            loss = self.__criterion(outputs, captions)\n",
    "            loss.backward()\n",
    "            self.__optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            #print(loss)\n",
    "        return training_loss/len(self.__train_loader)\n",
    "\n",
    "    # TODO: Perform one Pass on the validation set and return loss value. You may also update your best model here.\n",
    "    def __val(self):\n",
    "        self.__model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, captions, _) in enumerate(self.__val_loader):\n",
    "                images = images.to('cuda')\n",
    "                captions = captions.to('cuda')\n",
    "                outputs = self.__model(images, captions)\n",
    "                outputs = torch.transpose(outputs, 1, 2)\n",
    "                captions = captions[:,1:]\n",
    "                outputs = outputs[:, :, :-1]\n",
    "                loss = self.__criterion(outputs, captions)\n",
    "                val_loss += loss.item()\n",
    "        #print(val_loss)\n",
    "        return val_loss/len(self.__val_loader)\n",
    "    def stripPadding(self, lst):\n",
    "        res = []\n",
    "        for i in lst:\n",
    "            if i <= 3:\n",
    "                if i == 2:\n",
    "                    break\n",
    "                continue\n",
    "            else:\n",
    "                res.append(i)\n",
    "        #print(res)\n",
    "        return res\n",
    "    # TODO: Implement your test function here. Generate sample captions and evaluate loss and\n",
    "    #  bleu scores using the best model. Use utility functions provided to you in caption_utils.\n",
    "    #  Note than you'll need image_ids and COCO object in this case to fetch all captions to generate bleu scores.\n",
    "    def test(self):\n",
    "        self.__model.eval()\n",
    "        test_loss = []\n",
    "        bleu1_score = []\n",
    "        bleu4_score = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iter, (images, captions, img_ids) in enumerate(self.__test_loader):\n",
    "                images = images.to('cuda')\n",
    "                outputs = self.__model.generateCaption(images, self.__stochastic)\n",
    "                for i in range(outputs.shape[0]):\n",
    "                    references = self.__coco_test.imgToAnns[img_ids[i]]\n",
    "                    caption = []\n",
    "                    for reference in references:\n",
    "                        caption.append(reference['caption'].split())\n",
    "                    output = self.__vocab.ids2words(self.stripPadding(outputs[i].tolist()))\n",
    "                    \n",
    "                    #print(output, caption)\n",
    "                    bleu1_score.append(bleu1(caption, output))\n",
    "                    bleu4_score.append(bleu4(caption, output))\n",
    "                captions = captions[:,1:]\n",
    "                outputs = outputs[:, :, :-1]\n",
    "                loss = self.__criterion(outputs, captions)\n",
    "                test_loss.append(loss)\n",
    "\n",
    "        result_str = \"Test Performance: Loss: {}, Bleu1: {}, Bleu4: {}\".format(sum(test_loss)/len(test_loss), sum(bleu1_score)/len(bleu1_score), sum(bleu4_score)/len(bleu4_score))\n",
    "        self.__log(result_str)\n",
    "        return test_loss, sum(bleu1_score)/len(bleu1_score), sum(bleu4_score)/len(bleu4_score)\n",
    "\n",
    "    def __save_model(self):\n",
    "        root_model_path = os.path.join(self.__experiment_dir, 'latest_model.pt')\n",
    "        model_dict = self.__model.state_dict()\n",
    "        state_dict = {'model': model_dict, 'optimizer': self.__optimizer.state_dict()}\n",
    "        torch.save(state_dict, root_model_path)\n",
    "\n",
    "    def __record_stats(self, train_loss, val_loss):\n",
    "        self.__training_losses.append(train_loss)\n",
    "        self.__val_losses.append(val_loss)\n",
    "\n",
    "        self.plot_stats()\n",
    "\n",
    "        write_to_file_in_dir(self.__experiment_dir, 'training_losses.txt', self.__training_losses)\n",
    "        write_to_file_in_dir(self.__experiment_dir, 'val_losses.txt', self.__val_losses)\n",
    "\n",
    "    def __log(self, log_str, file_name=None):\n",
    "        print(log_str)\n",
    "        log_to_file_in_dir(self.__experiment_dir, 'all.log', log_str)\n",
    "        if file_name is not None:\n",
    "            log_to_file_in_dir(self.__experiment_dir, file_name, log_str)\n",
    "\n",
    "    def __log_epoch_stats(self, start_time):\n",
    "        time_elapsed = datetime.now() - start_time\n",
    "        time_to_completion = time_elapsed * (self.__epochs - self.__current_epoch - 1)\n",
    "        train_loss = self.__training_losses[self.__current_epoch]\n",
    "        val_loss = self.__val_losses[self.__current_epoch]\n",
    "        summary_str = \"Epoch: {}, Train Loss: {}, Val Loss: {}, Took {}, ETA: {}\\n\"\n",
    "        summary_str = summary_str.format(self.__current_epoch + 1, train_loss, val_loss, str(time_elapsed),\n",
    "                                         str(time_to_completion))\n",
    "        self.__log(summary_str, 'epoch.log')\n",
    "\n",
    "    def plot_stats(self):\n",
    "        e = len(self.__training_losses)\n",
    "        x_axis = np.arange(1, e + 1, 1)\n",
    "        plt.figure()\n",
    "        plt.plot(x_axis, self.__training_losses, label=\"Training Loss\")\n",
    "        plt.plot(x_axis, self.__val_losses, label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(self.__name + \" Stats Plot\")\n",
    "        plt.savefig(os.path.join(self.__experiment_dir, \"stat_plot.png\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
